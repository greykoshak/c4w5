<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Введение в Tensorflow</title>
</head>
<body>
<div><p>
    В ближайших видио мы с вами поговорим о том, как применять Python для обучения и для создания своих нейронных сетей. Сейчас существует несколько популярных фреймворков для решения таких задач. Мы с вами будем работать с TensorFlow. Огромной популярностью в последнее время пользуются также PyTorch, который немного архитектурно по-другому устроен. Однако, принцип абсолютно тот же. Если вы понимаете, как работают нейронные сети, выучить соответствующий фреймворк TensorFlow , либо PyTorch, либо какой-то еще - это задача одной двух недель. У них немного отличается синтаксис и парадигма, однако, в сущности, это те же самые математические модели, с которыми мы с вами познакомились на этой неделе. Итак, давайте приступим. TensoFrlow у вас уже установлен. Давайте импортируем его. Импортируем в переменную tf. Так делается обычно. И начнем работать. Для начала объявим константу "Hello world!" строковую, а именно с этого мы начнем, как обычно начинают все программисты. И в следующей ячейке мы запускаем сессию, вычисляем соответствующую переменную. Что же такое сессия? Все вычисления в TensoFrlow происходят в рамках какого-то вычислительного графа. В этом графе есть определенный оператор и есть данные. Операторы передают данные друг к другу. И таким образом у нас получаются вычисления. Вычисления в этом графе происходят в рамках определенной сессии. Эту сессию мы создаем. Мы создаем объект сессии и запускаем в этой сессии переменную "Hello". Выполнив переменную "Hello", мы получаем результат. Выводим его и закрываем сессию. Точно так же можно сделать только с помощью контекстного менеджера стандартного. Как вы видите абсолютно такой же результат. Итак, TensoFrlow работает в рамках сессии. В определенной сессии запускается вычислительный граф. Давайте попробуем добавить немного параметров в наш вычислительный граф. Создадим две константы a и b обычные integer, числовые константы. Они записываются в наш граф, когда мы их определяем. И создадим переменные c и d, которые будут являться уже массивами одномерными. Точно так же мы можем создавать многомерные массивы или, в сущности, других типов. Воспользуемся контекстным менеджером и попробуем просто вывести наши переменные. Однако просто выводить переменные не так интересно. Нам интересно производить какие-то вычислительные операции на нашем графе. Именно это мы и сделаем. Давайте мы сложим a и b, перемножим a и b и сделаем то же самое c и d. Запустим нашу ячейку и получим результат. Итак, в TensoFrlow есть вычислительный граф, в который мы можем записывать определенные данные и добавлять операторы. Вычисляя наш граф, вычисляя определенный оператор, мы получаем результат. Здесь мы получаем результат сложения a и b. Например, результат сложения c и d. Точно так же можно добавлять операторы более сложные. Об этом мы поговорим чуть позже. Еще один важный тип, с которым нужно познакомиться - это placeholder. Если в случае константы у нас сразу задано значение и оно никогда не меняется, потому что это константа, то placeholder говорит о том, что нам нужно добавить наш вычислительный граф, определенный объект, который потом получит свое значение. В момент выполнения нашего графа. Давайте создадим два placeholder-а a и b. И добавим также, кроме placeholder-ов, две операции: сложения, стандартная операция TensorFlow , вычислительная, которая принимает a и b, и перемножение, которое тоже принимает a и b. Давайте их добавим в наш вычислительный граф. Итак, теперь в рамках сессии мы можем вычислять наши операции с помощью определенных функций, отдельных операторов. Для того чтобы передать значение в наш оператор, мы используем параметр, атрибут feed_dict. Как видите, в словаре этом мы передаем соответствующие параметры нашим placeholder-ам, чтобы они получили значение. Placeholder-ы обязаны получать значение. Давайте запишем нашу сессию и получим результат. Таким образом, мы запускаем в нашей сессии соответствующий оператор, передаем ему значение placeholder, потому что оператору требуется значение, для того чтобы вычислить результат, и выводим это в нашу ячейку. Также, обратите внимание, мы делаем дополнительную переменную writer, в которой записывается какая-то информация о нашей сессии, о нашем вычислительном графе. Вы можете посмотреть информацию о вычислительном графе с помощью программы TensorBoard. Запустите программу TensorBoard в консоли и вы увидите, как выглядит ваш вычислительный граф. Вы можете с ним производить определенные операции, добавлять туда дополнительные знания, значения и в принципе смотреть, как у вас выглядит ваш вычислительный граф, чтобы, например, отладить его работу. Однако, конечно же, просто складывать и перемножать числа не так интересно. Давайте решим более сложную задачу. А конкретно, вначале разберемся с линейной регрессией. Так как, вычислительный граф позволяет вам работать с разными сущностями - это просто парадигма вычисления, где у вас есть какие-то операторы, есть данные и вычисляется результат, то мы можем, конечно, не только обучать нейронные сети, а делать в принципе абсолютно все что угодно. Давайте импортируем уже знакомые вам библиотеки для визуализации и numpy. И создадим задачи регрессии. Делать мы это будем с помощью функции make_regression, которая создает какой-то набор данных, который можно использовать для того, чтобы обучать нейронную сеть, обучать линейную регрессию, конечно же. Создадим регрессию с таким шумом, с таким random_state, и запишем это все в наши параметры x_train и y_train. И также нормализуем их, чтобы нам обучать нашу модель. Давайте попробуем вывести, это просто числа, с каким-то шумом. Они позволят нам провести определенную прямую в этих точках. Создадим два placeholder, x и y уже по знакомому вам правилу - это будут placeholder-ы типа float. И создадим два новых типа данных, две Variable для переменных. Переменная эта в отличии от константы, значения в вычислительном графе, которые могут менять свое значение. В данном случае мы инициализируем их случайным образом. А потом они могут меняться, потому что в момент обучения модели мы, конечно, хотим чтобы наши параметры изменялись. Здесь у нас есть веса и какой-то bias turn нашей линейной регрессии. С этим вы уже знакомы. Итак, чтобы вычислить предсказание по уже знакомой вам схеме, мы должны сложить, перемножить x и веса, и сложить их с bias turn. Именно это мы и делаем с помощью стандартных операций TensorFlow. Здесь мы получаем какую-то node, какую-то вершину в графе, которая соответствует получению предсказаний. Это вершина взаимодействует с предыдущими операциями, такими как сложение и перемножение. Итак, давайте объявим еще один placeholder, который будет отвечать за learning_rate, то есть как у нас модель наша изменяет веса. Обычно learning_rate делается константой. Часто делается константа learning_rate, есть определенные методы оптимизации, которые изменяют автоматически внутри себя learning_rate. Мы сделаем его placeholder-ом, чтобы мы могли передавать разные значения learning_rate. И, например, уменьшать его по мере обучения, часто это бывает полезным. Также мы определим функцию потерь с помощью стандартных операций TensorFlow. Здесь мы будем просто минимизировать квадратичную функцию ошибки. Смотрите, мы вычитаем предсказанное значение из нашего графа со значением корректных лейблов. И возводим в квадрат разницу. И говорим, что мы хотим уменьшать сумму квадратов этой разности. И нормируем мы, конечно, количество samples в нашей выборке. В принципе, стандартные операции, которые вы уже знаете. Будем обучать с помощью градиентного спуска с определенным learning_rate и минимизируя вот такую вот функцию потерь, которую мы выше определили. Итак, мы определили функцию потерь и наш оптимизатор. Давайте инициализируем глобальные переменные. Это нужно всегда делать для того, чтобы, например, variable приняли параметры, которые мы им указали. И осталось только запустить нашу сессию и обучать нашу модель. Будем обучать в течение 1000 эпох. Вызовем нашу, получим верх нашей сессии, инициализируем переменные, которые мы объявили. Для начала сдадим learning_rate 0.1. И давайте по мере наших эпох получать числа и обучать линейную регрессию. Чтобы ее обучить, нам нужно запустить сессию с оптимизатором, который будет оптимизировать заданную функцию потерь с заданным learning_rate. И будем передавать ему наши данные, на которых он будет обучаться. Здесь он будет обучаться на x и y batch с определенным learning_rate. И каждую сотую эпоху мы будем выводить отладочную информацию, для того чтобы понять, как хорошо наша модель обучается. Давайте запустим нашу модель и, как вы видите, у нас пошло вычисление. Итак, еще раз, у нас есть сессия и есть наш вычислительный граф. Чтобы нам обучить нашу модель, мы запускаем наш оптимизационный алгоритм на функции потерь. Функция потерь определена так, что минимизирует нашу квадратичную ошибку предсказания. Предсказание, в свою очередь, строится на основе линейной модели так, как мы с вами разбирали на третьей неделе. Итак, наша модель обучилась. Давайте посмотрим как же хорошо она описала наши данные. Просто выведем наши x_train, y_train - корректные объекты. Да, как вы видите, мы обучаемся на всей выборке. Здесь нам не важно какое-то качество на отложенной выборке. Мы просто посмотрим как наша модель предсказывает. Выводим x_train, y_train и выводим x_train против предсказания, которое делает наша модель. Как видите здесь мы берем наши веса. Берем наши объекты из x_train и прибавляем к ним bias turn. Давайте это запустим. Как видите, наша линия достаточно неплохо описала данные - это, действительно, уже обученная линейная регрессия. Давайте закроем сессию. Итак, мы с вами познакомились с фреймворком TensorFlow. TensoFrlow позволяет вам описать вычислительный граф или Computational Graph, в который вы можете добавить данные и добавить какие-то операторы. Эти операторы могут передавать данные друг-другу. Операторы могут зависеть друг от друга. Таким образом, вы строите вычислительный граф, который приходит к определенному результату. Чтобы запустить этот граф вам нужно создать сессию и запустить граф в рамках сессии. Таким образом, вы можете обучать вашу модель. Мы с вами посмотрели на то, как делать какие-то простые операции вроде сложения. Также научились решать задачу линейной регрессии.
</p></div>
</body>
</html>